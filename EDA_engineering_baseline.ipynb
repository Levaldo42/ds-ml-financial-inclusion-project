{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Financial Inclusion in Africa - Notebook\n",
    "\n",
    "# Part 1 Data prep and cleaning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "# dataframe and plotting\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# machine learning\n",
    "#from lightgbm import LGBMClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load data\n",
    "df = pd.read_csv('data/Train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()\n",
    "# Column uniqueid is NOT unique. Only unique in combination with country"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.bank_account.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n",
    "# Many categorical variables -> need to create dummies\n",
    "# bank_account = target = needs to be numerical as well (contains yes and no)\n",
    "# No NaNs, which is nice!"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data exploration was mainly done here: https://medium.com/analytics-vidhya/why-you-need-to-explore-your-data-how-you-can-start-13de6f29c8c1\n",
    "\n",
    "Main takeaways: 14% have a bankaccount, 86% don't. Highly imbalanced. Might need tweaking for modelling!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bank account distribution among category levels\n",
    "ctdf = df.select_dtypes(include='object').drop([\"bank_account\",\"uniqueid\"], axis=1)\n",
    "ctdf_y = df.bank_account\n",
    "\n",
    "\n",
    "for column_name in ctdf.columns:\n",
    "    print(pd.crosstab(ctdf[column_name], ctdf_y,normalize=\"index\"))\n",
    "    print(\"____________\")\n",
    "\n",
    "\n",
    "# Main takeaways:\n",
    "# - No cellphone = most likely no bank account\n",
    "# - Differences among countries\n",
    "# - Small differences between rural and urban and also between genders. Smaller as expected. \n",
    "# education_level and job_type have a high influence and are POTENTIALLY correlated.\n",
    "# Need to research banking practice in Africa !!!\n",
    "\n",
    "pd.crosstab(ctdf.job_type, ctdf.education_level,normalize=\"index\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.crosstab(ctdf.job_type, ctdf.education_level,normalize=\"index\")\n",
    "\n",
    "# There are - as expected - correlations between job and education\n",
    "\n",
    "pd.crosstab(ctdf.country, ctdf.education_level,normalize=\"index\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert all categories into dummies\n",
    "cats = [\"country\", \"bank_account\", \"location_type\", \"cellphone_access\",\"gender_of_respondent\", \"relationship_with_head\", \"marital_status\", \"education_level\", \"job_type\"] \n",
    "df_dumm = pd.get_dummies(df, prefix_sep=\"_\", columns = cats ,drop_first=True)\n",
    "\n",
    "\n",
    "# Drop 'uniqueid'\n",
    "df_dumm.drop(\"uniqueid\",inplace=True, axis= 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train-Test-Split\n",
    "y = df_dumm[[\"bank_account_Yes\"]]\n",
    "X = df_dumm.drop(\"bank_account_Yes\", axis = 1)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, stratify=y) # Default 25% in test\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Min-Max-Scaling\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "X_train_scaled\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model\n",
    "\n",
    "- Metric: Our stakeholder - the UN - wants an accurate and unbiased view of the banking situation in Africa. We therefore think that the accuracy - although the data is not balanced - is a good starter metric\n",
    "\n",
    "- Baseline: To showcase the stakeholder what is possible with data science. Very simple but assumption driven. Selection of 1 or 2 features. \n",
    "\n",
    "Idea: Rural and no/early_education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dumm.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_baseline = []\n",
    "\n",
    "X_test_scaled_df = pd.DataFrame(X_test_scaled,columns = df_dumm.drop(\"bank_account_Yes\",axis=1).columns)\n",
    "\n",
    "for index, row in X_test_scaled_df.iterrows():\n",
    "    if row[\"location_type_Urban\"] or row['education_level_Other/Dont know/RTA'] or row['education_level_Secondary education'] or row['education_level_Tertiary education'] or row[ 'education_level_Vocational/Specialised training']:\n",
    "        y_pred_baseline.append(1)\n",
    "    else:\n",
    "        y_pred_baseline.append(0)\n",
    "\n",
    "print(y_pred_baseline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "print(confusion_matrix(y_test, y_pred_baseline))\n",
    "print(classification_report(y_test, y_pred_baseline))\n",
    "\n",
    "# Our baseline model has an accuracy of 55% and many false positives."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "test = DecisionTreeClassifier()\n",
    "\n",
    "test.fit(X_train_scaled, y_train)\n",
    "\n",
    "y_pred = test.predict(X_test_scaled)\n",
    "\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('data/X_train_scaled.csv', X_train_scaled, delimiter=',')\n",
    "np.savetxt('data/X_test_scaled.csv', X_test_scaled, delimiter=',')\n",
    "np.savetxt('data/y_test.csv', y_test, delimiter=',')\n",
    "np.savetxt('data/y_train.csv', y_train, delimiter=',')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import imblearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from imblearn.under_sampling import RandomUnderSampler, NearMiss\n",
    "\n",
    "# rus = NearMiss(version=3)\n",
    "# X_rus, y_rus = rus.fit_resample(X_train_scaled, y_train)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from sklearn.tree import DecisionTreeClassifier\n",
    "# from sklearn.neighbors import KNeighborsClassifier\n",
    "# test = DecisionTreeClassifier()\n",
    "\n",
    "# test.fit(X_rus, y_rus)\n",
    "\n",
    "# y_pred = test.predict(X_test_scaled)\n",
    "\n",
    "# print(confusion_matrix(y_test, y_pred))\n",
    "# print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ideas to improve\n",
    "\n",
    "- Get rid of year\n",
    "- transform skewed numerical variables to more normally distributed values (log-scaling) -> age and number of householdmembers\n",
    "\n",
    "\n",
    "- Unbalanced target variable. Play around with balanced bootstrapping: https://machinelearningmastery.com/tactics-to-combat-imbalanced-classes-in-your-machine-learning-dataset/\n",
    "https://machinelearningmastery.com/random-oversampling-and-undersampling-for-imbalanced-classification/"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
